<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Mxiny</title>
<meta name="description" content="温故而知新" />
<link rel="shortcut icon" href="http://mxiny.com/favicon.ico?v=1583630133783">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.2/animate.min.css">

<link rel="stylesheet" href="http://mxiny.com/styles/main.css">



  </head>
  <body>
    <div id="app" class="main px-4 flex flex-col lg:flex-row">
      <div id="sidebar" class="sidebar-wrapper lg:static lg:w-1/4">
  <div class="lg:sticky top-0">
    <div class="sidebar-content">
      <div class="flex lg:block p-4 lg:px-0 items-center fixed lg:static lg:block top-0 right-0 left-0 bg-white z-50">
        <i class="ri-menu-2-line lg:mt-4 text-2xl cursor-pointer animated fadeIn" onclick="openMenu()"></i>
        <a href="http://mxiny.com">
          <img class="animated fadeInLeft avatar rounded-lg mx-4 lg:mt-32 lg:mx-0 mt-0 lg:w-24 lg:h-24 w-12 w-12" src="http://mxiny.com/images/avatar.png?v=1583630133783" alt="">
        </a>
        <h1 class="animated fadeInLeft lg:text-4xl font-extrabold lg:mt-8 mt-0 text-xl" style="animation-delay: 0.2s">Mxiny</h1>
      </div>
      
        <div class="animated fadeInLeft" style="animation-delay: 0.4s">
          <p class="my-4 text-gray-600 font-light hidden lg:block">
            文章目录
          </p>
          <div class="toc-container hidden lg:block">
            <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#title">Title</a></li>
<li><a href="#problem">Problem</a></li>
<li><a href="#motivation">Motivation</a></li>
<li><a href="#method">Method</a></li>
<li><a href="#experiment">Experiment</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      
    </div>
  </div>
</div>

<div class="menu-container">
  <i class="ri-arrow-left-line text-2xl cursor-pointer animated fadeIn close-menu-btn" onclick="closeMenu()"></i>
  <div>
    
      
        <a href="/" class="menu" style="animation-delay: 0s">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu" style="animation-delay: 0.2s">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu" style="animation-delay: 0.4s">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu" style="animation-delay: 0.6000000000000001s">
          关于
        </a>
      
    
  </div>
  <div class="site-footer">
    <div class="py-4 text-gray-700">Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a></div>
    <a class="rss" href="http://mxiny.com/atom.xml" target="_blank">RSS</a>
  </div>
</div>
<div class="mask" onclick="closeMenu()">
</div>
      <div class="content-wrapper py-32 lg:p-8 lg:w-3/4 post-detail animated fadeIn">
        <h1 class="text-3xl font-bold lg:mt-16">读论文二</h1>
        <div class="text-sm text-gray-700 lg:my-8">
          2020-03-04 / 4 min read
        </div>
        
        <div class="post-content yue">
          <h2 id="title">Title</h2>
<p>2019 JMLR Decoupling sparsity and smoothness in the dirichlet variational autoencoder topic model</p>
<h2 id="problem">Problem</h2>
<ul>
<li>
<p><strong>There is a trade-off between sparsity and smoothness in Dirichlet distributions.</strong></p>
<ul>
<li>The Dirichlet distribution encourages the sparsity in the latent variables. However, authors find that the desired sparsity is at odds with the generalization performance of the model.</li>
<li>In the case of variational autoencoders (VAEs), the trade off is that:
<ul>
<li>Either the model is sparse and achieves a good reconstruction error, but has a high KL-divergence term and thus a low log-likelihood of the model</li>
<li>Or it avoids low settings of the prior and thereby achieves a better log-likelihood at the cost of a higher reconstruction error.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>There is no differentiable non-centered reparameterization function for the Dirichlet distribution.</p>
</li>
</ul>
<h2 id="motivation">Motivation</h2>
<p>To identify the trade-off between sparsity and smoothness and provide an adapted neural network architecture to decouple them.</p>
<h2 id="method">Method</h2>
<ul>
<li>横向比较</li>
</ul>
<figure data-type="image" tabindex="1"><img src="http://mxiny.com/post-images/1583626929639.png" alt="" loading="lazy"></figure>
<p>a 为Dirichlet分布的参数，b为稀疏性系数。DVAE和DVAE Sparse的区别在于前者的b为1。</p>
<ul>
<li>
<p>内部探究</p>
<ul>
<li>模型结构</li>
</ul>
</li>
</ul>
<figure data-type="image" tabindex="2"><img src="http://mxiny.com/post-images/1583626938494.png" alt="" loading="lazy"></figure>
<p>​				 这里引入batchnorm的原因是为了改善 Component Collapsing 问题。</p>
<ul>
<li>
<p>ELBO和梯度的推导，详看论文。</p>
</li>
<li>
<p>VAE中的 Component Collapsing 问题。</p>
<ul>
<li>
<p>What?</p>
<p>This is the problem of a local minimum, which leads to parameters that are equal to the prior and thus, many or all topics are the same. <strong>Topic redundancy</strong></p>
</li>
<li>
<p>Why?</p>
<p>It occurs because it is often easier for the model to minimize the KL-divergence than to minimize the reconstruction error.</p>
</li>
<li>
<p>How to deal with it?</p>
<ul>
<li>use much lower learning rates (NVDM)</li>
<li>annealing of the KL-divergence (Bowman et al., 2016)</li>
<li>batch normalization and dropout (Srivastava and Sutton, 2017, 2018)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="experiment">Experiment</h2>
<ul>
<li>除了 perplexity 和 NPMI（coherence）以外，还引入了 topic redundancy（越低越好）：</li>
</ul>
<figure data-type="image" tabindex="3"><img src="http://mxiny.com/post-images/1583626864052.png" alt="" loading="lazy"></figure>
<ul>
<li>
<p>DVAE，coherence最高，但perplexity却非常高， topic redundancy一般。</p>
</li>
<li>
<p>DVAE Sparse，coherence一般，但是perplexity与DVAE和其他基于近似Dirichlet分布的方法相比较低，且topic redundancy低。</p>
</li>
<li>
<p>分析：</p>
<ul>
<li>以Dirichlet分布为先验的模型在coherence上都好于以高斯分布为先验的模型（NVDM）。This further underlines the argument by Srivastava and Sutton (2017) that the sparsity induced by the Dirichlet indeed leads to higher topic coherence.</li>
<li>DVAE的perplexity却非常高是因为 KL-divergence 收敛到 0，则可以通过引入稀疏性系数，即DVAE Sparse来缓解。这表明了the coupling of sparsity and smoothness is responsible for the high perplexity scores. Also perplexity scores are not always meaningful when comparing different topic models.</li>
<li>计算KL散度有解析式计算、采样计算两种方法。后者有利于增加coherence。</li>
</ul>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<ul>
<li>Authors have introduced a variational autoencoder with a Dirichlet prior called DVAE.</li>
<li>A trade-off between sparsity and smoothness was identified, leading to high perplexity as well as topic coherence scores.</li>
<li>To test our hypothesis about the reason for the high perplexity scores, a new model called DVAE Sparse was introduced. DVAE Sparse decouples sparsity and smoothness and thus enables lower perplexity scores on the one hand while on the other hand the topic coherence is still competitive.</li>
<li>The topic quality was also measured in terms of topic redundancy which is a good indicator for component collapsing as opposed to topic coherence.</li>
</ul>

        </div>

        
          <a class="animated fadeInUp p-2 items-center text-sm text-gray-700 border hover:bg-gray-300 leading-none rounded-full flex lg:inline-flex m-4 " href="http://mxiny.com/tag/racTE-Nv7">
            <span class="flex-auto">论文</span>
          </a>
        


        <div class="flex justify-between py-8">
          

          
            <div class="next-post">
              <a href="http://mxiny.com/post/lun-wen-yan-du">
                <h3 class="post-title">
                  读论文一
                  <i class="ri-arrow-right-line"></i>
                </h3>
              </a>
            </div>
          
        </div>

        
          
            <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>

  var gitalk = new Gitalk({
    clientID: '49a42d81ba5f02692218',
    clientSecret: 'ae43637c37e6670fbe9766b52d033f49c4f5c4f9',
    repo: 'mxiny.github.io',
    owner: 'mxiny',
    admin: ['mxiny'],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

          

          
        

      </div>
    </div>

    <script src="http://mxiny.com/media/prism.js"></script>  
<script>

Prism.highlightAll()
let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

// This should probably be throttled.
// Especially because it triggers during smooth scrolling.
// https://lodash.com/docs/4.17.10#throttle
// You could do like...
// window.addEventListener("scroll", () => {
//    _.throttle(doThatStuff, 100);
// });
// Only not doing it here to keep this Pen dependency-free.

window.addEventListener("scroll", event => {
  let fromTop = window.scrollY;

  mainNavLinks.forEach((link, index) => {
    let section = document.getElementById(decodeURI(link.hash).substring(1));
    let nextSection = null
    if (mainNavLinks[index + 1]) {
      nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
    }
    if (section.offsetTop <= fromTop) {
      if (nextSection) {
        if (nextSection.offsetTop > fromTop) {
          link.classList.add("current");
        } else {
          link.classList.remove("current");    
        }
      } else {
        link.classList.add("current");
      }
    } else {
      link.classList.remove("current");
    }
  });
});


document.addEventListener("DOMContentLoaded", function() {
  var lazyImages = [].slice.call(document.querySelectorAll(".post-feature-image.lazy"));

  if ("IntersectionObserver" in window) {
    let lazyImageObserver = new IntersectionObserver(function(entries, observer) {
      entries.forEach(function(entry) {
        if (entry.isIntersecting) {
          let lazyImage = entry.target
          lazyImage.style.backgroundImage = `url(${lazyImage.dataset.bg})`
          lazyImage.classList.remove("lazy")
          lazyImageObserver.unobserve(lazyImage)
        }
      });
    });

    lazyImages.forEach(function(lazyImage) {
      lazyImageObserver.observe(lazyImage)
    })
  } else {
    // Possibly fall back to a more compatible method here
  }
});

const menuContainer = document.querySelector('.menu-container')
const menus = document.querySelectorAll('.menu-container .menu')
const mask = document.querySelector('.mask')
const contentWrapper = document.querySelector('.content-wrapper')
const latestArticle = document.querySelector('.latest-article')
const readMore = document.querySelector('.read-more')
const indexPage = document.querySelector('.index-page')

const isHome = location.pathname === '/'
if (latestArticle) {
  latestArticle.style.display = isHome ? 'block' : 'none'
  readMore.style.display = isHome ? 'block' : 'none'
  indexPage.style.display = isHome ? 'none' : 'block'
}

const openMenu = () => {
  menuContainer.classList.add('open')
  menus.forEach(menu => {
    menu.classList.add('animated', 'fadeInLeft')
  })
  mask.classList.add('open')
  contentWrapper.classList.add('is-second')
}

const closeMenu = () => {
  menuContainer.classList.remove('open')
  menus.forEach(menu => {
    menu.classList.remove('animated', 'fadeInLeft')
  })
  mask.classList.remove('open')
  contentWrapper.classList.remove('is-second')
}
</script>
  
  </body>
</html>
