<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" >

<title>读论文二 | Mxiny</title>

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="shortcut icon" href="https://mxiny.github.io/favicon.ico?v=1583630775165">
<link rel="stylesheet" href="https://mxiny.github.io/styles/main.css">


  
    <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css" />
  

  


<link rel="stylesheet" href="https://unpkg.com/aos@next/dist/aos.css" />
<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>



    <meta name="description" content="Title
2019 JMLR Decoupling sparsity and smoothness in the dirichlet variational autoencoder topic model
Problem


There ..." />
    <meta name="keywords" content="论文" />
  </head>
  <body>
    <div id="app" class="main">

      <div class="sidebar" :class="{ 'full-height': menuVisible }">
  <div class="top-container" data-aos="fade-right">
    <div class="top-header-container">
      <a class="site-title-container" href="https://mxiny.github.io">
        <img src="https://mxiny.github.io/images/avatar.png?v=1583630775165" class="site-logo">
        <h1 class="site-title">Mxiny</h1>
      </a>
      <div class="menu-btn" @click="menuVisible = !menuVisible">
        <div class="line"></div>
      </div>
    </div>
    <div>
      
        
          <a href="/" class="site-nav">
            首页
          </a>
        
      
        
          <a href="/archives" class="site-nav">
            归档
          </a>
        
      
        
          <a href="/tags" class="site-nav">
            标签
          </a>
        
      
        
          <a href="/post/about" class="site-nav">
            关于
          </a>
        
      
    </div>
  </div>
  <div class="bottom-container" data-aos="flip-up" data-aos-offset="0">
    <div class="social-container">
      
        
          <a class="social-link" href="https://github.com/mxiny" target="_blank">
            <i class="fab fa-github"></i>
          </a>
        
      
        
      
        
      
        
      
        
      
    </div>
    <div class="site-description">
      温故而知新
    </div>
    <div class="site-footer">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | <a class="rss" href="https://mxiny.github.io/atom.xml" target="_blank">RSS</a>
    </div>
  </div>
</div>


      <div class="main-container">
        <div class="content-container" data-aos="fade-up">
          <div class="post-detail">
            <h2 class="post-title">读论文二</h2>
            <div class="post-date">2020-03-04</div>
            
            <div class="post-content" v-pre>
              <h2 id="title">Title</h2>
<p>2019 JMLR Decoupling sparsity and smoothness in the dirichlet variational autoencoder topic model</p>
<h2 id="problem">Problem</h2>
<ul>
<li>
<p><strong>There is a trade-off between sparsity and smoothness in Dirichlet distributions.</strong></p>
<ul>
<li>The Dirichlet distribution encourages the sparsity in the latent variables. However, authors find that the desired sparsity is at odds with the generalization performance of the model.</li>
<li>In the case of variational autoencoders (VAEs), the trade off is that:
<ul>
<li>Either the model is sparse and achieves a good reconstruction error, but has a high KL-divergence term and thus a low log-likelihood of the model</li>
<li>Or it avoids low settings of the prior and thereby achieves a better log-likelihood at the cost of a higher reconstruction error.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>There is no differentiable non-centered reparameterization function for the Dirichlet distribution.</p>
</li>
</ul>
<h2 id="motivation">Motivation</h2>
<p>To identify the trade-off between sparsity and smoothness and provide an adapted neural network architecture to decouple them.</p>
<h2 id="method">Method</h2>
<ul>
<li>横向比较</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://mxiny.github.io/post-images/1583626929639.png" alt="" loading="lazy"></figure>
<p>a 为Dirichlet分布的参数，b为稀疏性系数。DVAE和DVAE Sparse的区别在于前者的b为1。</p>
<ul>
<li>
<p>内部探究</p>
<ul>
<li>模型结构</li>
</ul>
</li>
</ul>
<figure data-type="image" tabindex="2"><img src="https://mxiny.github.io/post-images/1583626938494.png" alt="" loading="lazy"></figure>
<p>​				 这里引入batchnorm的原因是为了改善 Component Collapsing 问题。</p>
<ul>
<li>
<p>ELBO和梯度的推导，详看论文。</p>
</li>
<li>
<p>VAE中的 Component Collapsing 问题。</p>
<ul>
<li>
<p>What?</p>
<p>This is the problem of a local minimum, which leads to parameters that are equal to the prior and thus, many or all topics are the same. <strong>Topic redundancy</strong></p>
</li>
<li>
<p>Why?</p>
<p>It occurs because it is often easier for the model to minimize the KL-divergence than to minimize the reconstruction error.</p>
</li>
<li>
<p>How to deal with it?</p>
<ul>
<li>use much lower learning rates (NVDM)</li>
<li>annealing of the KL-divergence (Bowman et al., 2016)</li>
<li>batch normalization and dropout (Srivastava and Sutton, 2017, 2018)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="experiment">Experiment</h2>
<ul>
<li>除了 perplexity 和 NPMI（coherence）以外，还引入了 topic redundancy（越低越好）：</li>
</ul>
<figure data-type="image" tabindex="3"><img src="https://mxiny.github.io/post-images/1583626864052.png" alt="" loading="lazy"></figure>
<ul>
<li>
<p>DVAE，coherence最高，但perplexity却非常高， topic redundancy一般。</p>
</li>
<li>
<p>DVAE Sparse，coherence一般，但是perplexity与DVAE和其他基于近似Dirichlet分布的方法相比较低，且topic redundancy低。</p>
</li>
<li>
<p>分析：</p>
<ul>
<li>以Dirichlet分布为先验的模型在coherence上都好于以高斯分布为先验的模型（NVDM）。This further underlines the argument by Srivastava and Sutton (2017) that the sparsity induced by the Dirichlet indeed leads to higher topic coherence.</li>
<li>DVAE的perplexity却非常高是因为 KL-divergence 收敛到 0，则可以通过引入稀疏性系数，即DVAE Sparse来缓解。这表明了the coupling of sparsity and smoothness is responsible for the high perplexity scores. Also perplexity scores are not always meaningful when comparing different topic models.</li>
<li>计算KL散度有解析式计算、采样计算两种方法。后者有利于增加coherence。</li>
</ul>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<ul>
<li>Authors have introduced a variational autoencoder with a Dirichlet prior called DVAE.</li>
<li>A trade-off between sparsity and smoothness was identified, leading to high perplexity as well as topic coherence scores.</li>
<li>To test our hypothesis about the reason for the high perplexity scores, a new model called DVAE Sparse was introduced. DVAE Sparse decouples sparsity and smoothness and thus enables lower perplexity scores on the one hand while on the other hand the topic coherence is still competitive.</li>
<li>The topic quality was also measured in terms of topic redundancy which is a good indicator for component collapsing as opposed to topic coherence.</li>
</ul>

            </div>
            
              <div class="tag-container">
                
                  <a href="https://mxiny.github.io/tag/racTE-Nv7" class="tag">
                    论文
                  </a>
                
              </div>
            
            
              <div class="next-post">
                <div class="next">下一篇</div>
                <a href="https://mxiny.github.io/post/lun-wen-yan-du">
                  <h3 class="post-title">
                    读论文一
                  </h3>
                </a>
              </div>
            

            
              
                <div id="gitalk-container" data-aos="fade-in"></div>
              

              
            

          </div>

        </div>
      </div>
    </div>

    <script src="https://unpkg.com/aos@next/dist/aos.js"></script>
<script type="application/javascript">

AOS.init();

var app = new Vue({
  el: '#app',
  data: {
    menuVisible: false,
  },
})

</script>





  
    <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
    <script>

      var gitalk = new Gitalk({
        clientID: '49a42d81ba5f02692218',
        clientSecret: 'ae43637c37e6670fbe9766b52d033f49c4f5c4f9',
        repo: 'mxiny.github.io',
        owner: 'mxiny',
        admin: ['mxiny'],
        id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
        distractionFreeMode: false  // Facebook-like distraction free mode
      })

      gitalk.render('gitalk-container')

    </script>
  

  




  </body>
</html>
